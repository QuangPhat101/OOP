# ğŸ“ Chatbot Trá»£ LÃ½ Há»c Láº­p TrÃ¬nh - Äá»“ Ãn OOP

## ğŸ“‹ MÃ´ táº£ dá»± Ã¡n
Chatbot AI há»— trá»£ há»c láº­p trÃ¬nh, xÃ¢y dá»±ng báº±ng C++ vá»›i kiáº¿n trÃºc OOP. Sá»­ dá»¥ng Ollama API Ä‘á»ƒ táº¡o tráº£i nghiá»‡m chat streaming (hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i theo thá»i gian thá»±c).

## ğŸ—ï¸ Kiáº¿n trÃºc OOP

### 1. **Class Message** (`Message.h`, `Message.cpp`)
- **Má»¥c Ä‘Ã­ch**: Äáº¡i diá»‡n cho má»™t tin nháº¯n trong cuá»™c há»™i thoáº¡i
- **Thuá»™c tÃ­nh**: 
  - `role` (user/assistant)
  - `content` (ná»™i dung)
  - `timestamp` (thá»i gian)
- **PhÆ°Æ¡ng thá»©c**: `display()`, `toJson()`, getters

### 2. **Class OllamaClient** (`OllamaClient.h`, `OllamaClient.cpp`)
- **Má»¥c Ä‘Ã­ch**: Xá»­ lÃ½ giao tiáº¿p vá»›i Ollama API
- **Thuá»™c tÃ­nh**: `apiUrl`, `model`, `curl`
- **PhÆ°Æ¡ng thá»©c**: 
  - `sendMessage()` - gá»­i tin nháº¯n vá»›i streaming
  - `StreamCallback()` - xá»­ lÃ½ response streaming
  - `setModel()`, `getModel()`

### 3. **Class ChatSession** (`ChatSession.h`, `ChatSession.cpp`)
- **Má»¥c Ä‘Ã­ch**: Quáº£n lÃ½ phiÃªn chat vÃ  lá»‹ch sá»­ há»™i thoáº¡i
- **Thuá»™c tÃ­nh**: `history`, `client`, `isActive`
- **PhÆ°Æ¡ng thá»©c**: 
  - `start()`, `stop()` - Ä‘iá»u khiá»ƒn phiÃªn
  - `sendUserMessage()` - gá»­i tin nháº¯n
  - `clearHistory()`, `showHistory()` - quáº£n lÃ½ lá»‹ch sá»­
  - `showHelp()` - hiá»ƒn thá»‹ trá»£ giÃºp

## ğŸ“¦ Cáº¥u trÃºc thÆ° má»¥c
```
chatbot-oop/
â”œâ”€â”€ Message.h
â”œâ”€â”€ Message.cpp
â”œâ”€â”€ OllamaClient.h
â”œâ”€â”€ OllamaClient.cpp
â”œâ”€â”€ ChatSession.h
â”œâ”€â”€ ChatSession.cpp
â”œâ”€â”€ main.cpp
â”œâ”€â”€ ngrok_url.h
â”œâ”€â”€ json.hpp          # Tá»« nlohmann/json
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

## âš™ï¸ YÃªu cáº§u há»‡ thá»‘ng
- **Compiler**: g++ vá»›i C++11 trá»Ÿ lÃªn
- **ThÆ° viá»‡n**: 
  - libcurl (cÃ i Ä‘áº·t: `sudo apt install libcurl4-openssl-dev`)
  - nlohmann/json (header-only, Ä‘Ã£ include)
- **Ollama server**: Äang cháº¡y vÃ  expose qua ngrok

## ğŸš€ CÃ¡ch build vÃ  cháº¡y

### Build:
```bash
make
```

### Cháº¡y:
```bash
./chatbot
```

Hoáº·c:
```bash
make run
```

### Clean:
```bash
make clean
```

## ğŸ’¡ CÃ¡ch sá»­ dá»¥ng

### CÃ¡c lá»‡nh cÃ³ sáºµn:
- `/help` - Hiá»ƒn thá»‹ hÆ°á»›ng dáº«n
- `/history` - Xem lá»‹ch sá»­ há»™i thoáº¡i
- `/clear` - XÃ³a lá»‹ch sá»­
- `/exit` hoáº·c `/quit` - ThoÃ¡t chÆ°Æ¡ng trÃ¬nh

### VÃ­ dá»¥ há»™i thoáº¡i:
```
ğŸ‘¤ Báº¡n: Giáº£i thÃ­ch con trá» trong C++

ğŸ¤– AI: Con trá» lÃ  biáº¿n lÆ°u Ä‘á»‹a chá»‰ bá»™ nhá»›...
(streaming response)

ğŸ‘¤ Báº¡n: Cho tÃ´i vÃ­ dá»¥ code

ğŸ¤– AI: ÄÃ¢y lÃ  vÃ­ dá»¥ vá» con trá»:
int x = 10;
int* ptr = &x;
...
```

## ğŸ¯ TÃ­nh nÄƒng ná»•i báº­t

1. âœ… **Streaming Response**: Hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i theo thá»i gian thá»±c nhÆ° ChatGPT
2. âœ… **Context Memory**: LÆ°u lá»‹ch sá»­ há»™i thoáº¡i Ä‘á»ƒ AI nhá»› ngá»¯ cáº£nh
3. âœ… **System Prompt**: ÄÆ°á»£c tá»‘i Æ°u cho há»— trá»£ há»c láº­p trÃ¬nh
4. âœ… **Command System**: CÃ¡c lá»‡nh dá»… dÃ¹ng (/help, /clear...)
5. âœ… **OOP Design**: Ãp dá»¥ng Ä‘áº§y Ä‘á»§ tÃ­nh cháº¥t OOP (Encapsulation, Abstraction)

## ğŸ”§ Tuá»³ chá»‰nh

### Äá»•i model:
Trong `main.cpp`:
```cpp
OllamaClient client(OLLAMA_API_URL, "llama3");  // Äá»•i model
```

### Äá»•i system prompt:
Trong `OllamaClient.cpp`, method `sendMessage()`:
```cpp
{"content", "Báº¡n lÃ  trá»£ lÃ½ AI..."}  // Sá»­a á»Ÿ Ä‘Ã¢y
```

## ğŸ“ BÃ¡o cÃ¡o Ä‘á»“ Ã¡n

### CÃ¡c Ä‘iá»ƒm cáº§n trÃ¬nh bÃ y:
1. **PhÃ¢n tÃ­ch yÃªu cáº§u**: Chatbot há»c láº­p trÃ¬nh vá»›i streaming
2. **Thiáº¿t káº¿ OOP**: 
   - Class diagram (3 classes)
   - Má»‘i quan há»‡: ChatSession HAS-A OllamaClient, USES Message
3. **TÃ­nh cháº¥t OOP Ã¡p dá»¥ng**:
   - Encapsulation (private/public)
   - Abstraction (áº©n chi tiáº¿t CURL, streaming)
   - CÃ³ thá»ƒ má»Ÿ rá»™ng: Inheritance (táº¡o SpecializedChatbot extends ChatSession)
4. **Káº¿t quáº£**: Demo cháº¡y chÆ°Æ¡ng trÃ¬nh

## ğŸ› Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p

### Lá»—i: `undefined reference to curl_*`
â†’ Thiáº¿u `-lcurl` khi compile. DÃ¹ng Makefile Ä‘Ã£ cung cáº¥p.

### Lá»—i: Cannot connect to API
â†’ Kiá»ƒm tra `ngrok_url.h` cÃ³ Ä‘Ãºng URL khÃ´ng, Ollama server cÃ³ Ä‘ang cháº¡y khÃ´ng.

### Streaming khÃ´ng hoáº¡t Ä‘á»™ng
â†’ Kiá»ƒm tra `"stream": true` trong `OllamaClient.cpp`

## ğŸ“š TÃ i liá»‡u tham kháº£o
- [Ollama API Documentation](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [nlohmann/json](https://github.com/nlohmann/json)
- [libcurl](https://curl.se/libcurl/)

---
**Sinh viÃªn thá»±c hiá»‡n**: [TÃªn cá»§a báº¡n]  
**Lá»›p**: [Lá»›p cá»§a báº¡n]  
**MÃ´n há»c**: Láº­p trÃ¬nh hÆ°á»›ng Ä‘á»‘i tÆ°á»£ng (OOP)